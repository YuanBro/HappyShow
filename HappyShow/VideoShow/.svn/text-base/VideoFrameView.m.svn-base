//
//  VideoFrameView.m
//  VideoShow
//
//  Created by Jerry Chen  on 14-10-29.
//  Copyright (c) 2014年 energy. All rights reserved.
//
#import "VideoFrameView.h"
#import "qxMediaObject.h"
#import <AssetsLibrary/AssetsLibrary.h>

typedef void (^GenerateFrameComplementionHandler)(NSMutableArray *frames, float spi, Float64 duraion);

/** 时间轴组件 */
@interface VideoFrameView()
{
    UIView *pView;// 用于响应滑动事件
    UIView *contentView;
    UIView *frameMark;// 中间的白色标记指向所预览的帧
    UIView *selectView;// 用于显示单击选中的片段区域
    __block Float64 framesTotalWidth;// 计算出的所有帧的总宽度
}
@property (nonatomic,strong) NSArray *mediaArray;;

@end

@implementation VideoFrameView

@synthesize mediaArray;

- (id)initWithFrame:(CGRect)rect mediaArray:(NSArray*)medArray
{
    self = [super initWithFrame:rect];
    if (self) {
        self.scrollEnable = YES;
        mediaArray = medArray;
        // 响应拖动事件
        pView = [[UIView alloc] initWithFrame:CGRectMake(0, 0, rect.size.width, rect.size.height)];
        [self addSubview:pView];
        
        // 中间的白线
        frameMark = [[UIView alloc] initWithFrame:CGRectMake(rect.size.width/2, 0, 2, rect.size.height)];
        frameMark.backgroundColor = [UIColor whiteColor];
        [self addSubview:frameMark];
        
        UIPanGestureRecognizer *gestureRecognizer = [[UIPanGestureRecognizer alloc] initWithTarget:self action:@selector(handlePanGesture:)];
        [pView addGestureRecognizer:gestureRecognizer];
        
        [self loadFrames];
    }
    return self;
}

- (void)setSelectRectFrom:(float)startSecond to:(float)endSecond
{
    if(!contentView){
        return;
    }
    float x = startSecond * FrameWidthPerSecond + self.frame.size.width / 2;
    float w = (endSecond - startSecond) * FrameWidthPerSecond;
    if (w <= 0) {
        return;// 不再继续绘制
    }
    CGRect rect = CGRectMake(x, 0, w, self.frame.size.height);
    if(!selectView){
        selectView = [[UIView alloc] initWithFrame:rect];
        selectView.backgroundColor = [UIColor colorWithRed:221/255.0 green:107/255.0 blue:111/255.0 alpha:0.8];
        [contentView addSubview:selectView];
    }else{
        selectView.frame = rect;
    }
}

- (void)clearSelectRect
{
    if(selectView){
        [selectView removeFromSuperview];
        selectView = nil;
    }
}

- (void)addContentView:(UIView*)view
{
    if(view && contentView){
        [contentView addSubview:view];
    }
}

- (float)currentPosition
{
    return frameMark.frame.origin.x + pView.bounds.origin.x;
}

- (float)currentSecond
{
    return pView.bounds.origin.x/FrameWidthPerSecond;
}

- (void)reloadFrames
{
    [self loadFrames];
}

- (void)scrollToSecond:(float)second tapFlag:(BOOL)tapFlag sendEvent:(BOOL)flag
{
    if(second >= 0){
        [self scrollTo:CGPointMake(FrameWidthPerSecond * second, 0) tapFlag:tapFlag sendEvent:flag];
    }
}

- (float)totalFramesWidth
{
    return framesTotalWidth;
}

-(float)startTimeOfContentView:(UIView*)view
{
    return (view.frame.origin.x - self.frame.size.width/2 + 0.5)/FrameWidthPerSecond;
}

- (void)handlePanGesture:(UIPanGestureRecognizer *)gestureRecognizer
{
    if(!self.scrollEnable){
        return;
    }
    
    switch (gestureRecognizer.state) {
        case UIGestureRecognizerStateBegan:
            if([self.delegate respondsToSelector:@selector(videoFrameViewPanDidStart)]){
                [self.delegate videoFrameViewPanDidStart];
            }
            break;
            
        case UIGestureRecognizerStateChanged:{
            CGPoint translation = [gestureRecognizer translationInView:pView];
            CGRect bounds = pView.bounds;
            CGFloat newBoundsOriginX = bounds.origin.x - translation.x;
            CGFloat newBoundsOriginY = bounds.origin.y - translation.y;
            [self scrollTo:CGPointMake(newBoundsOriginX, newBoundsOriginY) tapFlag:NO sendEvent:YES];
            [gestureRecognizer setTranslation:CGPointZero inView:pView];
        }
            break;
            
        case UIGestureRecognizerStateEnded:
        case UIGestureRecognizerStateCancelled:
        case UIGestureRecognizerStateFailed: {
            
            if([self.delegate respondsToSelector:@selector(videoFrameViewPanDidEnd)]){
                [self.delegate videoFrameViewPanDidEnd];
            }
        }
            break;
        default:
            break;
    }
    
}

- (void)handleContentViewTapGesture:(UITapGestureRecognizer*)gestureRecognizer
{
    if([self.delegate respondsToSelector:@selector(videoFrameContentViewTapped)]){
        [self.delegate videoFrameContentViewTapped];
    }
}

// 滚动
- (void)scrollTo:(CGPoint)point tapFlag:(BOOL)tapFlag sendEvent:(BOOL)flag
{
    CGRect bounds = self.bounds;
    CGFloat newBoundsOriginX = point.x;
    CGFloat minBoundsOriginX = 0.0;
    CGFloat maxBoundsOriginX = contentView.frame.size.width - bounds.size.width - 0.5;
    bounds.origin.x = fmax(minBoundsOriginX, fmin(newBoundsOriginX, maxBoundsOriginX));
    //
    CGFloat newBoundsOriginY = point.y;
    CGFloat minBoundsOriginY = 0.0;
    CGFloat maxBoundsOriginY = contentView.frame.size.height - bounds.size.height;
    bounds.origin.y = fmax(minBoundsOriginY, fmin(newBoundsOriginY, maxBoundsOriginY));
    pView.bounds = bounds;
    if([self.delegate respondsToSelector:@selector(videoFrameView:didScrollTo:tapFlag:)] && flag){
        [self.delegate videoFrameView:self didScrollTo:pView.bounds.origin.x/FrameWidthPerSecond tapFlag:tapFlag];
    }
}

- (void)loadFrames
{
    [self generateFramesWithCompletionHanlder:^(NSMutableArray *frames, float spi, Float64 totalDuration){
        CGRect imgRect;
        UIImage *image;
        UIImageView *tmpImgView;
        if(contentView){
            [contentView removeFromSuperview];
            contentView = nil;
        }
        CGFloat half = self.frame.size.width/2;
        framesTotalWidth = totalDuration * FrameWidthPerSecond;
        contentView = [[UIView alloc] initWithFrame:CGRectMake(0, 0, framesTotalWidth + self.frame.size.width, 45)];
        [pView addSubview:contentView];
        
        UITapGestureRecognizer *tapGesture = [[UITapGestureRecognizer alloc] initWithTarget:self action:@selector(handleContentViewTapGesture:)];
        [contentView addGestureRecognizer:tapGesture];
        //
        for(int i = 0; i < frames.count; i++){
            image = frames[i];
            tmpImgView = [[UIImageView alloc] initWithImage:image];
            
            if(i != frames.count - 1){
                imgRect = CGRectMake(i * 45 + half, 0, 45, 45);
            }else{
                if(frames.count * spi > totalDuration){
                    float delta = frames.count *spi - totalDuration;
                    imgRect = CGRectMake(i *45 + half, 0, (spi - delta)*45/spi, 45);
                }else{
                    imgRect = CGRectMake(i * 45 + half, 0, 45, 45);
                }
            }
            tmpImgView.frame = imgRect;
            [contentView addSubview:tmpImgView];
        }
        //
        [self scrollTo:CGPointMake(0, 0) tapFlag:NO sendEvent:YES];
        [self bringSubviewToFront:frameMark];
        if([self.delegate respondsToSelector:@selector(videoFrameLoadDone)]){
            [self.delegate videoFrameLoadDone];
        }
    }];
}

// 生成帧序列---先创建出图片
- (void)generateFramesWithCompletionHanlder:(GenerateFrameComplementionHandler)complementionHandler
{
    __weak VideoFrameView * weakSelf=self;
    NSMutableArray *destArray = [[NSMutableArray alloc] init];
    
    int spi = 3;//seconds per image
    __block CGFloat delta = 0;
    __block CGFloat totalDuration = 0;
    ALAssetsLibrary *alLibrary = [[ALAssetsLibrary alloc] init];
    dispatch_semaphore_t semapthore = dispatch_semaphore_create(0);
    dispatch_async(dispatch_queue_create("serial_queue", NULL), ^{
        if(weakSelf.mediaArray){
            int frameCount;
            qxMediaObject *mediaObj = nil;
            NSArray *temp = nil;
            
            CGSize size = CGSizeMake(45, 45);
            for (int i = 0; i < weakSelf.mediaArray.count; i++) {
                delta = destArray.count * spi - totalDuration;
                mediaObj = weakSelf.mediaArray[i];
                if(mediaObj.eType == eMT_Video){
                    frameCount = ceil((CMTimeGetSeconds(mediaObj.actualTimeRange.duration) - delta)/spi);
                    temp = [weakSelf getCountFrame:frameCount andPictureSize:size fromVideo:mediaObj];
                    if(temp){
                        [destArray addObjectsFromArray:temp];
                    }
                    dispatch_semaphore_signal(semapthore);
                }else if(mediaObj.eType == eMT_Photo){
                    if(delta < CMTimeGetSeconds(mediaObj.actualTimeRange.duration)){
                        [alLibrary assetForURL:[NSURL URLWithString:mediaObj.strFilePath] resultBlock:^(ALAsset *asset){
                            UIImage *img = [UIImage imageWithCGImage:asset.thumbnail];
                            if(img){
                                int count = ceil((CMTimeGetSeconds(mediaObj.actualTimeRange.duration) - delta)/3);
                                while (count) {
                                    [destArray addObject:img];
                                    count --;
                                }
                            }
                            dispatch_semaphore_signal(semapthore);
                        } failureBlock:^(NSError *error){
                            dispatch_semaphore_signal(semapthore);
                        }];
                    }else{
                        dispatch_semaphore_signal(semapthore);
                    }
                }
                dispatch_semaphore_wait(semapthore, DISPATCH_TIME_FOREVER);
                totalDuration += CMTimeGetSeconds(mediaObj.actualTimeRange.duration);
            }
            dispatch_async(dispatch_get_main_queue(), ^{
                
                if(complementionHandler){
                    complementionHandler(destArray,spi,totalDuration);
                }
            });
        }
    });
}

// 提取视频关键帧
- (NSArray*)getCountFrame:(NSInteger)count andPictureSize:(CGSize)size fromVideo:(qxMediaObject*)videoObj
{
    NSMutableArray *frames = [[NSMutableArray alloc] init];
    AVAsset *myAsset = [[AVURLAsset alloc] initWithURL:[NSURL URLWithString:videoObj.strFilePath] options:nil];
    AVAssetImageGenerator *imageGenerator = [AVAssetImageGenerator assetImageGeneratorWithAsset:myAsset];
    imageGenerator.maximumSize = CGSizeMake(size.width*[UIScreen mainScreen].scale, size.height*[UIScreen mainScreen].scale);
    //
    NSError *error;
    CMTime actualTime;
    Float64 durationSeconds = CMTimeGetSeconds(videoObj.actualTimeRange.duration);
    Float64 timeUnit = durationSeconds/count;
    //
    for (int i=0; i < count; i++){
        
        CMTime timeFrame = CMTimeMakeWithSeconds(i * timeUnit + CMTimeGetSeconds(videoObj.actualTimeRange.start), 600);
        
        CGImageRef halfWayImage = [imageGenerator copyCGImageAtTime:timeFrame actualTime:&actualTime error:&error];
        UIImage *videoScreen;
        videoScreen = [[UIImage alloc] initWithCGImage:halfWayImage scale:[UIScreen mainScreen].scale orientation:UIImageOrientationDown];
        if(!videoScreen){
            videoScreen = [[UIImage alloc] init];
        }
        [frames addObject:videoScreen];
        CGImageRelease(halfWayImage);
    }
    return frames;
}

@end
